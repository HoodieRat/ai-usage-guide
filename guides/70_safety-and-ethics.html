<!-- filepath: guides/70_safety-and-ethics.html -->
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="Govern ChatGPT usage with clear risk classes, approvals, and incident handling procedures.">
  <title>Safety and Ethics | Everyday AI Guide</title>
  <link rel="icon" href="../assets/favicon.ico">
  <link rel="stylesheet" href="../css/main.css">
  <link rel="stylesheet" href="../css/prism.css">
</head>
<body data-base=".." class="theme-auto">
  <noscript>
    <div class="noscript-notice">JavaScript powers navigation, search, and theme controls. Enable it for the full experience.</div>
  </noscript>

  <header class="site-header" role="banner">
    <button class="mobile-nav-toggle" type="button" data-mobile-nav-toggle aria-expanded="false" aria-controls="sidebar">
      <span class="sr-only">Toggle navigation</span>
      <span aria-hidden="true"></span>
    </button>
    <a class="brand" href="../index.html">
      <img src="../assets/logo.svg" alt="Everyday AI Guide logo" class="brand-mark">
      <span class="brand-name">Everyday AI Guide</span>
    </a>
    <form class="search-form" role="search">
      <label class="sr-only" for="site-search">Search guides</label>
      <input id="site-search" type="search" name="q" placeholder="Search guides..." autocomplete="off" data-search-input>
    </form>
    <button type="button" class="theme-toggle" data-theme-toggle aria-pressed="false">
      <img src="../assets/icons/sun.svg" alt="" data-icon="sun">
      <img src="../assets/icons/moon.svg" alt="" data-icon="moon">
      <span class="sr-only">Toggle dark mode</span>
    </button>
  </header>

  <div class="layout">
    <nav id="sidebar" class="sidebar" aria-label="Guide navigation" data-nav></nav>

    <main id="content" class="site-main" role="main">
      <article class="guide">
        <header class="guide-header">
          <p class="eyebrow">Safety &amp; Quality</p>
          <h1>Safety and Ethics</h1>
          <p class="intro">Operationalize AI safety—classify risks, manage approvals, and route incidents so teams innovate without crossing ethical or regulatory lines.</p>
        </header>

        <section class="callout info">
          <p><strong>Risk taxonomy:</strong> Align AI use cases with your enterprise risk matrix before unlocking expanded permissions.</p>
        </section>

        <section class="callout warning">
          <p><strong>Legal counsel:</strong> Involve privacy, security, and compliance teams early. Never ship policies without review from accountable owners.</p>
        </section>

        <section id="what-youll-learn" class="guide-section">
          <h2>What you’ll learn</h2>
          <ul>
            <li>Mapping AI activities to risk classes and approval tiers.</li>
            <li>Designing guardrail prompts and policy acknowledgements for risky workflows.</li>
            <li>Setting up incident intake, escalation, and postmortem practices.</li>
            <li>Embedding ethical decision frameworks into day-to-day usage.</li>
          </ul>
        </section>

        <section id="prerequisites" class="guide-section">
          <h2>Prerequisites</h2>
          <ul>
            <li>Documented governance model (information security, privacy, legal contacts).</li>
            <li>Clear definition of sensitive data classes and regulatory obligations.</li>
            <li>Existing incident response process you can extend to AI issues.</li>
          </ul>
        </section>

        <section id="step-by-step" class="guide-section">
          <h2>Step-by-step</h2>
          <ol>
            <li><strong>Define risk classes.</strong> Categorize AI use cases (Low, Moderate, High, Critical) based on data sensitivity, autonomy, and business impact. Document examples for each class.</li>
            <li><strong>Assign controls.</strong> Map guardrails to every class—required prompts, human reviewers, logging requirements, approval cadence.</li>
            <li><strong>Publish decision tree.</strong> Create a quick diagnostic flow so users know which approvals they need before executing a workflow.</li>
            <li><strong>Instrument logging.</strong> Capture prompts, files, outputs, and approver IDs for all Moderate+ classes. Retain logs per policy.</li>
            <li><strong>Train the team.</strong> Run workshops or videos covering acceptable use, escalation contacts, and examples of good/bad judgment.</li>
            <li><strong>Handle incidents.</strong> Stand up an intake form and pager rotation. Define triage timelines and notification thresholds.</li>
            <li><strong>Iterate ethically.</strong> Review quarterly with a cross-functional council. Track metrics, audit samples, and update guardrails.</li>
          </ol>
        </section>

        <section id="copy-assets" class="guide-section">
          <h2>Copy &amp; paste assets</h2>
          <h3>Risk classification matrix</h3>
          <pre><code>| Class | Example use cases | Data allowed | Required controls |
|-------|-------------------|--------------|-------------------|
| Low   | Internal FAQ drafting | Public or approved internal | No approval; auto-logging |
| Moderate | Marketing copy with customer segments | Aggregated metrics | Team lead approval; prompt log |
| High | Financial modeling, customer comms | Non-public PII | Director approval; legal review |
| Critical | Decisions impacting safety or compliance | Regulated data | CISO sign-off; red-team review |
</code></pre>
          <h3>Incident intake prompt</h3>
          <pre><code>Event summary: {{what happened}}
Date/time: {{UTC}}
Risk class: {{low/mod/high/critical}}
Impact: {{data exposed, customers affected}}
Containment steps: {{actions}}
Help needed: {{legal/privacy/security}}
Attachments: {{logs, transcript, screenshots}}</code></pre>
        </section>

        <section id="output-contract" class="guide-section">
          <h2>Output contract</h2>
          <ul>
            <li>Risk classification rubric documented and stored in governance repository.</li>
            <li>Approval matrix with named roles and service-level expectations.</li>
            <li>Incident response workflow integrated with existing ticketing or pager systems.</li>
            <li>Quarterly review agenda with metrics and improvement backlog.</li>
          </ul>
        </section>

        <section id="metrics" class="guide-section">
          <h2>Metrics that matter</h2>
          <ul>
            <li><strong>Policy adherence:</strong> Percentage of AI requests with required approvals and logs attached.</li>
            <li><strong>Incident response time:</strong> Mean time from report to containment.</li>
            <li><strong>Ethics council actions:</strong> Number of policy updates or remediations per quarter.</li>
          </ul>
        </section>

        <section id="tips-and-pitfalls" class="guide-section">
          <h2>Tips &amp; pitfalls</h2>
          <ul>
            <li><strong>Use plain language:</strong> Policy docs should be readable by frontline staff, not just legal teams.</li>
            <li><strong>Simulate disasters:</strong> Run tabletop exercises with realistic prompts to test escalation speed.</li>
            <li><strong>Track exceptions:</strong> Maintain a waiver log for approved deviations and review them frequently.</li>
            <li><strong>Reward good calls:</strong> Celebrate teams that pause risky work and escalate—build a positive safety culture.</li>
          </ul>
        </section>

        <section id="recap" class="guide-section">
          <h2>Recap</h2>
          <p>Responsible AI operations rely on clear risk classes, empowered reviewers, and a culture that surfaces issues before they become incidents.</p>
        </section>

        <section id="acceptance" class="guide-section">
          <h2>Acceptance checklist</h2>
          <ul>
            <li>✅ Risk classes mapped to real use cases.</li>
            <li>✅ Approval matrix published and communicated.</li>
            <li>✅ Incident response hooks wired into existing processes.</li>
            <li>✅ Ethics council chartered with quarterly cadence.</li>
          </ul>
        </section>

        <footer class="guide-footer">
          <p class="update-note">Published October 31, 2025.</p>
        </footer>
      </article>
    </main>
  </div>

  <div class="search-panel" data-search-results hidden>
    <div class="search-results-header">
      <span class="search-results-title">Search results</span>
      <button type="button" class="search-close" data-search-close>Close</button>
    </div>
    <ul class="search-results-list" data-search-results-list></ul>
  </div>

  <script src="../js/nav.js" defer></script>
  <script src="../js/search.js" defer></script>
  <script src="../js/main.js" defer></script>
  <script src="../js/prism.js" defer></script>
</body>
</html>
